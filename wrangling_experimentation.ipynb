{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# import pandas as pd\n",
    "# from io import BytesIO\n",
    "\n",
    "# storage_client = storage.Client()\n",
    "\n",
    "# bucket_name = 'yt-charts-raw'\n",
    "\n",
    "# bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# df_list = []\n",
    "\n",
    "# # List all blobs in the bucket\n",
    "# blobs = bucket.list_blobs()\n",
    "\n",
    "# # Loop through each blob (file)\n",
    "# for blob in blobs:\n",
    "#     if blob.name.endswith('.csv'):\n",
    "#         # Download blob data into memory and create DataFrame\n",
    "#         byte_stream = BytesIO(blob.download_as_bytes())\n",
    "#         df = pd.read_csv(byte_stream)\n",
    "        \n",
    "#         # Add DataFrame to list\n",
    "#         df_list.append(df)\n",
    "\n",
    "# # Concatenate all DataFrames in the list into one DataFrame\n",
    "# weekly_charts = pd.concat(df_list)\n",
    "# weekly_charts.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'data/raw'\n",
    "files = os.listdir(path)\n",
    "\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(path, csv_file))\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenaing all .csvs into a one big file \n",
    "weekly_charts = pd.concat(df_list)\n",
    "weekly_charts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_artist(artist_names):\n",
    "    return artist_names.split(',')[0]\n",
    "\n",
    "# Apply the function to the \"Artist Names\" column and create a new column \"main_artist\"\n",
    "weekly_charts['main_artist'] = weekly_charts['Artist Names'].apply(get_first_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9100 entries, 0 to 9099\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      9100 non-null   int64  \n",
      " 1   Rank            9100 non-null   int64  \n",
      " 2   Previous Rank   7711 non-null   float64\n",
      " 3   Track Name      9100 non-null   object \n",
      " 4   Artist Names    9100 non-null   object \n",
      " 5   Weeks on Chart  9100 non-null   int64  \n",
      " 6   Views           9100 non-null   int64  \n",
      " 7   Weekly Growth   7711 non-null   object \n",
      " 8   YouTube URL     9100 non-null   object \n",
      " 9   week_open       9100 non-null   object \n",
      " 10  week_close      9100 non-null   object \n",
      " 11  main_artist     9100 non-null   object \n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 853.3+ KB\n"
     ]
    }
   ],
   "source": [
    "weekly_charts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spotipy import Spotify\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Initialize Spotipy\n",
    "sp = Spotify(auth_manager=SpotifyClientCredentials())\n",
    "\n",
    "\n",
    "# Step 1: Create artists_df from weekly_charts\n",
    "def get_artists_df():\n",
    "    artists_df = pd.DataFrame(weekly_charts[['main_artist']]).drop_duplicates()\n",
    "    artists_df.reset_index(drop=True, inplace=True)\n",
    "    return artists_df\n",
    "\n",
    "artists_df = get_artists_df()\n",
    "\n",
    "# Step 2: Get Spotify ID for each unique artist_name\n",
    "def get_artist_id(name):\n",
    "    try:\n",
    "        result = sp.search(q='artist:' + name, type='artist')\n",
    "        return result['artists']['items'][0]['id'] if result['artists']['items'] else None\n",
    "    except (IndexError, KeyError):\n",
    "        return None\n",
    "\n",
    "artist_ids = [get_artist_id(name) for name in artists_df['main_artist'].tolist()]\n",
    "artists_df['artist_id'] = artist_ids\n",
    "\n",
    "# Step 3: Get genres for each artist and create artist_genre DataFrame\n",
    "def get_artist_genre(artist_id):\n",
    "    try:\n",
    "        artist_info = sp.artist(artist_id)\n",
    "        return artist_info['genres']\n",
    "    except (TypeError, KeyError):\n",
    "        return []\n",
    "\n",
    "genre_rows = []\n",
    "for _, row in artists_df.iterrows():\n",
    "    genres = get_artist_genre(row['artist_id'])\n",
    "    for genre in genres:\n",
    "        genre_rows.append({'artist_id': row['artist_id'], 'genre': genre})\n",
    "\n",
    "artist_genre_df = pd.DataFrame(genre_rows)\n",
    "\n",
    "# Step 4: Create unique genres_df DataFrame\n",
    "genres_df = pd.DataFrame({'genre': artist_genre_df['genre'].unique()})\n",
    "\n",
    "# Save to CSV (Optional)\n",
    "# artists_df.to_csv('artists.csv', index=False)\n",
    "# genres_df.to_csv('genres.csv', index=False)\n",
    "# artist_genre_df.to_csv('artist_genre.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_artist</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xamã</td>\n",
       "      <td>5YwzDz4RJfTiMHS4tdR5Lf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paulo Pires</td>\n",
       "      <td>3whgFbrRxsOmYVrq3t4hCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MC Danny &amp; Zé Felipe</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tierry</td>\n",
       "      <td>4FUMTycjZlEY6ZxMgqNjC8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marcynho Sensação</td>\n",
       "      <td>4dnPDc045bVjibyATxVUOs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>MC Kauan</td>\n",
       "      <td>4TlVDevNpKDPEGlG805z6U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Sorriso Maroto &amp; Ferrugem</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Flora Matos</td>\n",
       "      <td>5Znx4PG5UsUitigaJnmZX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Sorriso Maroto &amp; Ludmilla</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>MC Saci</td>\n",
       "      <td>0kj68SnX4WCXwveyBbRX8p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   main_artist               artist_id\n",
       "0                         Xamã  5YwzDz4RJfTiMHS4tdR5Lf\n",
       "1                  Paulo Pires  3whgFbrRxsOmYVrq3t4hCY\n",
       "2         MC Danny & Zé Felipe                    None\n",
       "3                       Tierry  4FUMTycjZlEY6ZxMgqNjC8\n",
       "4            Marcynho Sensação  4dnPDc045bVjibyATxVUOs\n",
       "..                         ...                     ...\n",
       "533                   MC Kauan  4TlVDevNpKDPEGlG805z6U\n",
       "534  Sorriso Maroto & Ferrugem                    None\n",
       "535                Flora Matos  5Znx4PG5UsUitigaJnmZX3\n",
       "536  Sorriso Maroto & Ludmilla                    None\n",
       "537                    MC Saci  0kj68SnX4WCXwveyBbRX8p\n",
       "\n",
       "[538 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5YwzDz4RJfTiMHS4tdR5Lf</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5YwzDz4RJfTiMHS4tdR5Lf</td>\n",
       "      <td>trap brasileiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3whgFbrRxsOmYVrq3t4hCY</td>\n",
       "      <td>arrocha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3whgFbrRxsOmYVrq3t4hCY</td>\n",
       "      <td>arrochadeira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3whgFbrRxsOmYVrq3t4hCY</td>\n",
       "      <td>piseiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>5Znx4PG5UsUitigaJnmZX3</td>\n",
       "      <td>brazilian reggae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>5Znx4PG5UsUitigaJnmZX3</td>\n",
       "      <td>rap df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>5Znx4PG5UsUitigaJnmZX3</td>\n",
       "      <td>rap feminino nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0kj68SnX4WCXwveyBbRX8p</td>\n",
       "      <td>funk bh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0kj68SnX4WCXwveyBbRX8p</td>\n",
       "      <td>funk mtg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist_id                  genre\n",
       "0    5YwzDz4RJfTiMHS4tdR5Lf      brazilian hip hop\n",
       "1    5YwzDz4RJfTiMHS4tdR5Lf        trap brasileiro\n",
       "2    3whgFbrRxsOmYVrq3t4hCY                arrocha\n",
       "3    3whgFbrRxsOmYVrq3t4hCY           arrochadeira\n",
       "4    3whgFbrRxsOmYVrq3t4hCY                piseiro\n",
       "..                      ...                    ...\n",
       "633  5Znx4PG5UsUitigaJnmZX3       brazilian reggae\n",
       "634  5Znx4PG5UsUitigaJnmZX3                 rap df\n",
       "635  5Znx4PG5UsUitigaJnmZX3  rap feminino nacional\n",
       "636  0kj68SnX4WCXwveyBbRX8p                funk bh\n",
       "637  0kj68SnX4WCXwveyBbRX8p               funk mtg\n",
       "\n",
       "[638 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist ID for 'Gusttavo Lima' is 7MiDcPa6UiV3In7lIM71IN\n"
     ]
    }
   ],
   "source": [
    "artist_name = \"Gusttavo Lima\"\n",
    "filtered_artist = artists_df[artists_df['main_artist'] == artist_name]\n",
    "if not filtered_artist.empty:\n",
    "    gusttavo_lima_id = filtered_artist.iloc[0]['artist_id']\n",
    "    print(f\"The artist ID for '{artist_name}' is {gusttavo_lima_id}\")\n",
    "else:\n",
    "    print(f\"No artist found with the name '{artist_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brazilian hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trap brasileiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrocha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arrochadeira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>piseiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>funk das antigas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>funk melody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>afrofuturismo brasileiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>brazilian reggae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>rap feminino nacional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        genre\n",
       "0           brazilian hip hop\n",
       "1             trap brasileiro\n",
       "2                     arrocha\n",
       "3                arrochadeira\n",
       "4                     piseiro\n",
       "..                        ...\n",
       "142          funk das antigas\n",
       "143               funk melody\n",
       "144  afrofuturismo brasileiro\n",
       "145          brazilian reggae\n",
       "146     rap feminino nacional\n",
       "\n",
       "[147 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n",
      "No data returned for video ID: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize YouTube API\n",
    "youtube = build('youtube', 'v3', developerKey=os.environ['YOUTUBE_API_KEY'])\n",
    "\n",
    "# Extract YouTube IDs from the 'YouTube URL' column and place them in 'track_video_id_youtube'\n",
    "weekly_charts['track_video_id_youtube'] = weekly_charts['YouTube URL'].apply(lambda x: x.split(\"v=\")[1])\n",
    "\n",
    "# Initialize empty lists for published dates and tags\n",
    "# Initialize empty lists for published dates and tags\n",
    "published_dates = []\n",
    "tags_data = []\n",
    "\n",
    "# Iterate through YouTube video IDs to fetch data\n",
    "for video_id in weekly_charts['track_video_id_youtube']:\n",
    "    video_request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        id=video_id\n",
    "    )\n",
    "    video_response = video_request.execute()\n",
    "    \n",
    "    # Check if 'items' list is empty\n",
    "    if not video_response.get('items'):\n",
    "        print(f\"No data returned for video ID: {video_id}\")\n",
    "        published_dates.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Extracting published date\n",
    "    try:\n",
    "        published_date = video_response['items'][0]['snippet']['publishedAt']\n",
    "        published_dates.append(published_date)\n",
    "    except KeyError:\n",
    "        print(f\"Could not retrieve published date for video ID: {video_id}\")\n",
    "        published_dates.append(None)\n",
    "\n",
    "    # Extracting up to 3 tags\n",
    "    try:\n",
    "        tags = video_response['items'][0]['snippet'].get('tags', [])[:3]\n",
    "        for tag in tags:\n",
    "            tags_data.append({'track_video_id_youtube': video_id, 'tags': tag})\n",
    "    except KeyError:\n",
    "        print(f\"Could not retrieve tags for video ID: {video_id}\")\n",
    "\n",
    "# Create new DataFrame for tags\n",
    "tags_df = pd.DataFrame(tags_data)\n",
    "\n",
    "# Add published dates to the weekly_charts DataFrame\n",
    "weekly_charts['yt_published_dates'] = published_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9100 entries, 0 to 9099\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              9100 non-null   int64  \n",
      " 1   Rank                    9100 non-null   int64  \n",
      " 2   Previous Rank           7711 non-null   float64\n",
      " 3   Track Name              9100 non-null   object \n",
      " 4   Artist Names            9100 non-null   object \n",
      " 5   Weeks on Chart          9100 non-null   int64  \n",
      " 6   Views                   9100 non-null   int64  \n",
      " 7   Weekly Growth           7711 non-null   object \n",
      " 8   YouTube URL             9100 non-null   object \n",
      " 9   week_open               9100 non-null   object \n",
      " 10  week_close              9100 non-null   object \n",
      " 11  main_artist             9100 non-null   object \n",
      " 12  track_video_id_youtube  9100 non-null   object \n",
      " 13  yt_published_dates      8992 non-null   object \n",
      "dtypes: float64(1), int64(4), object(9)\n",
      "memory usage: 995.4+ KB\n"
     ]
    }
   ],
   "source": [
    "weekly_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "842"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(published_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_charts.to_csv(\"weekly_charts2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_info = weekly_charts[\"YouTube URL\"].unique().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet&id=dESfgB_UnZM&key=AIzaSyDCjq0gufGNNl8QWlUlv5jwzlEaj9-wd28&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\analytics\\gits\\mvp3_puc\\wrangling_experimentation.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Fetch video information from API\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m request \u001b[39m=\u001b[39m youtube\u001b[39m.\u001b[39mvideos()\u001b[39m.\u001b[39mlist(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     part\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msnippet\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mid\u001b[39m\u001b[39m=\u001b[39mvideo_id\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m response \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mexecute()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Check if 'items' is present and non-empty\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/analytics/gits/mvp3_puc/wrangling_experimentation.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m response \u001b[39mand\u001b[39;00m response[\u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\leo--\\.conda\\envs\\mvp3\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leo--\\.conda\\envs\\mvp3\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m HttpError(resp, content, uri\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet&id=dESfgB_UnZM&key=AIzaSyDCjq0gufGNNl8QWlUlv5jwzlEaj9-wd28&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists for DataFrame\n",
    "video_ids = []\n",
    "urls = []\n",
    "published_dates = []\n",
    "\n",
    "# List to collect tags data\n",
    "tags_data = []\n",
    "\n",
    "# Extract video ID from URLs and fetch data from YouTube API\n",
    "for url in track_info:\n",
    "    video_id = url.split(\"v=\")[1]\n",
    "    video_ids.append(video_id)\n",
    "    urls.append(url)\n",
    "\n",
    "    # Fetch video information from API\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet\",\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Check if 'items' is present and non-empty\n",
    "    if 'items' in response and response['items']:\n",
    "        item = response['items'][0]\n",
    "        snippet = item.get('snippet', {})\n",
    "\n",
    "        # Add published date\n",
    "        published_dates.append(snippet.get('publishedAt', None))\n",
    "\n",
    "        # Add tags to tags_data\n",
    "        if 'tags' in snippet:\n",
    "            tags = snippet['tags'][:5]  # Limit to 5 tags\n",
    "            for tag in tags:\n",
    "                tags_data.append({\"id\": video_id, \"tag\": tag})\n",
    "    else:\n",
    "        published_dates.append(None)\n",
    "\n",
    "# Create DataFrame for video IDs, URLs, and published dates\n",
    "info_df = pd.DataFrame({\n",
    "    \"id\": video_ids,\n",
    "    \"url\": urls,\n",
    "    \"published_date\": published_dates\n",
    "})\n",
    "\n",
    "# Create DataFrame for tags\n",
    "tags_df = pd.DataFrame(tags_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
